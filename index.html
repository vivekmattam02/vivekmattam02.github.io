<!DOCTYPE HTML>
<html lang="en">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Vivekananda Swamy Mattam</title>
    <meta name="author" content="Vivekananda Swamy Mattam">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Vivekananda Swamy Mattam - Masters Student in Mechatronics and Robotics at NYU Tandon. Research in autonomous navigation, visual SLAM, and robot perception.">
    <link rel="shortcut icon" href="images/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
<table style="width:100%;max-width:1100px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
    <tr style="padding:0px">
        <td style="padding:0px">
            
            <!-- Header Section: Photo + Bio -->
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr style="padding:0px">
                    <td style="padding:2.5%;width:63%;vertical-align:middle">
                        <p class="name" style="text-align: center;">
                            Vivekananda Swamy Mattam
                        </p>
                        <p>
                            I'm a Master's student in Mechatronics and Robotics at <a href="https://engineering.nyu.edu/">NYU Tandon School of Engineering</a>. 
                            Growing up in rural India, I saw firsthand the challenges of agriculture and inefficient processes. 
                            When I visited my grandfather's workplace at Mahindra and watched robots handle tasks that once required 
                            intense human labor, something clicked. That's when I realized robotics wasn't just about building cool 
                            machines but about creating systems that genuinely solve problems and reduce human burden.
                        </p>
                        <p>
                            NYU has been an incredible learning experience. I've had the chance to work on a Bell Labs funded project 
                            building high-speed navigation systems, train quadruped robots with reinforcement learning in Isaac Lab, 
                            and work on visual SLAM and perception for the VIP Self-Drive project. Before coming here, I interned at 
                            <a href="#">Xmachines</a>, an agricultural robotics startup, where I worked on sensor fusion and motion planning.
                        </p>
                        <p>
                            Right now, I'm looking for <strong>internship/full-time opportunities</strong> in robotics, autonomous systems, 
                            or applied AI. I want to work on projects where the technology actually matters, where robots are solving 
                            real problems for real people.
                        </p>
                        <p style="text-align:center">
                            <a href="mailto:vm2677@nyu.edu">Email</a> &nbsp;/&nbsp;
                            <a href="data/Vivek_Mattam_CV.pdf">CV</a> &nbsp;/&nbsp;
                            <a href="https://www.linkedin.com/in/vivek-mattam-a8590b23a">LinkedIn</a> &nbsp;/&nbsp;
                            <a href="https://github.com/vivekmattam02">GitHub</a>
                        </p>
                    </td>
                    <td style="padding:2.5%;width:40%;max-width:40%">
                        <a href="images/portfolio.jpg">
                            <img style="width:200px;height:200px;object-fit:cover;border-radius:50%;"
                                 alt="profile photo"
                                 src="images/portfolio.jpg"
                                 class="hoverZoomLink">
                        </a>
                    </td>
                </tr>
                </tbody>
            </table>

            <!-- Experience Section -->
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
                        <h2>Experience</h2>
                    </td>
                </tr>
                </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>

                <!-- Course Assistant -->
                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                            <img src="images/nyu.jpg" width="200" alt="Course Assistant">
                        </div>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <span class="papertitle">Course Assistant - Autonomous Mobile Robots</span>
                        <br>
                        <a href="https://engineering.nyu.edu/">NYU Tandon School of Engineering</a>
                        <br>
                        <em>2024 - Present</em>
                        <br>
                        <a href="https://vivekmattam02.github.io/amr-notes/">Course Materials</a>
                        <p></p>
                        <p>
                            Built all lecture materials for a graduate robotics course from scratch. Took the professor's
                            raw audio recordings and handwritten notes and transformed them into polished lecture slides
                            with custom diagrams and visualizations. A great exercise in breaking down complex robotics
                            concepts and presenting them in ways that actually make sense to students.
                        </p>
                    </td>
                </tr>

                <!-- Xmachines Intern -->
                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                            <img src="images/xmachines.jpg" width="200" alt="Xmachines">
                        </div>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <span class="papertitle">Robotics Engineering Intern</span>
                        <br>
                        Xmachines - Agricultural Robotics Startup
                        <br>
                        <em>2024</em>
                        <br>
                        <p></p>
                        <p>
                            Worked on autonomous systems for agricultural robots handling crop monitoring and harvesting.
                            Focused on sensor integration and optimization using MPU-6050 for motion tracking and Arducam
                            IMX219 for image processing on Ubuntu 22.04. Developed ROS-based motion planning solutions for
                            dynamic farm environments with embedded systems including Jetson Orin Nano, Arduino, and ESP32.
                        </p>
                    </td>
                </tr>

                </tbody>
            </table>

            <!-- Research/Projects Section Header -->
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
                        <h2>Projects</h2>
                        <p>
                            I'm interested in autonomous navigation, visual SLAM, robot perception, and deploying
                            learning-based systems on real robots.
                        </p>
                    </td>
                </tr>
                </tbody>
            </table>

            <!-- Projects List -->
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>

                <!-- 1) High-Speed Autonomous Navigation -->
                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                            <img src="images/highspeed_nav.jpg" width="200" alt="High-Speed Navigation">
                        </div>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <span class="papertitle">High-Speed Autonomous Navigation in Narrow Corridors</span>
                        <br>
                        <strong>Vivekananda Swamy Mattam</strong>
                        <br>
                        <em>NYU, Bell Labs Funded</em>, 2024-Present
                        <br>
                        <p></p>
                        <p>
                            Developed a ROS 2-based navigation framework for an Ackermann-steered RC car operating in corridors 
                            as narrow as 1.2 meters. Built a complete simulation environment in Gazebo Ignition with a custom 
                            URDF model addressing the four-bar linkage limitation inherent to Ackermann steering.
                        </p>
                        <p>
                            Implemented a camera-LiDAR fusion perception system with optical flow-based motion tracking and 
                            ego-motion compensation. Developed a racing line optimization algorithm that utilizes 92% of corridor 
                            width through outside-inside-outside cornering geometry. Integrated the full stack with Nav2, 
                            SLAM Toolbox, EKF localization, and MPPI control, creating a 60+ node architecture.
                        </p>
                        <p><em>Tech: ROS 2 Humble, Gazebo Ignition, Nav2, SLAM Toolbox, OpenCV, Python, C++</em></p>
                    </td>
                </tr>

                <!-- 2) Reinforcement Learning for Quadruped -->
                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                            <img src="images/quadruped_rl.gif" width="200" alt="Quadruped RL">
                        </div>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <span class="papertitle">Reinforcement Learning for Quadruped Locomotion</span>
                        <br>
                        <strong>Vivekananda Swamy Mattam</strong>
                        <br>
                        <em>NYU</em>, 2024
                        <br>
                        <p></p>
                        <p>
                            Trained a Unitree Go2 robot to walk using PPO in NVIDIA Isaac Lab. Implemented reward shaping 
                            for smooth actions, gait coordination (Raibert heuristic), and body stability. Added an actuator 
                            friction model with domain randomization for sim-to-real transfer. The final policy tracks velocity 
                            commands at nearly 2x the baseline targets on both flat and rough terrain.
                        </p>
                        <p><em>Tools: Isaac Lab, PyTorch, PPO, NYU HPC</em></p>
                    </td>
                </tr>

                <!-- 3) Robot Perception Project -->
                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                            <img src="images/perception.jpg" width="200" alt="Robot Perception">
                        </div>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <span class="papertitle">Visual Navigation and Robot Perception</span>
                        <br>
                        <strong>Vivekananda Swamy Mattam</strong>, Team Voyager
                        <br>
                        <em>ROB-GY 6203: Robot Perception, NYU</em>
                        <br>
                        <p></p>
                        <p>
                            Built a system that navigates a maze using only camera images, no GPS or odometry. Used CosPlace 
                            descriptors for place recognition and SuperGlue for geometric verification because matching by 
                            appearance alone kept giving false positives in similar-looking corridors. The system builds a 
                            topological graph and runs A* for planning.
                        </p>
                        <p>
                            Separately implemented 2D mapping using visual odometry with ORB features, multi-object tracking 
                            with YOLOv11 and ByteTrack, and wrote RANSAC plane fitting and ICP point cloud alignment from 
                            scratch for KITTI data.
                        </p>
                        <p><em>Tech: PyTorch, CosPlace, SuperGlue, OpenCV, YOLOv11, ByteTrack, Open3D</em></p>
                    </td>
                </tr>

                <!-- 4) HSRN Robot - Data Center -->
                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                            <img src="images/datacenter.jpg" width="200" alt="HSRN Robot">
                        </div>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <span class="papertitle">HSRN Robot - Data Center Automation</span>
                        <br>
                        <strong>Vivekananda Swamy Mattam</strong>
                        <br>
                        <em>NYU</em>, 2024-Present
                        <br>
                        <p></p>
                        <p>
                            Building a joystick-controlled robot for automating data center tasks. Focus on developing 
                            perception models and multi-robot coordination using sensor fusion to help robots navigate 
                            tight spaces and understand their environment in real time. Using Corelink's C++ client with 
                            ROS for inter-robot communication, with plans to transition from manual control to full autonomy.
                        </p>
                        <p><em>Tech: ROS, C++, Python, Corelink, Sensor Fusion</em></p>
                    </td>
                </tr>

                <!-- 5) VIP Self-Drive -->
                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                            <img src="images/vip.jpg" width="200" alt="VIP Self-Drive">
                        </div>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <span class="papertitle">NYU VIP Self-Drive - Autonomous Navigation & Visual SLAM</span>
                        <br>
                        <strong>Vivekananda Swamy Mattam</strong>
                        <br>
                        <em>NYU Vertically Integrated Projects</em>
                        <br>
                        <p></p>
                        <p>
                            Research project focused on autonomous indoor navigation using only visual SLAMâ€”no LIDAR, 
                            just a monocular camera. Handling path planning with A* and robot localization using ORB 
                            feature matching. The challenge is making a TurtleBot3 navigate unknown spaces with minimal 
                            sensor data, relying on smart graph-based planning and exploration strategies. Preparing 
                            for the Self-Drive Exploration & Navigation Challenge.
                        </p>
                        <p><em>Tech: ROS 2 Humble, A*, ORB SLAM, TurtleBot3, OpenCV, C++</em></p>
                    </td>
                </tr>

                <!-- 6) S.L.A.P. Hand -->
                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                            <img src="images/slap.jpg" width="200" alt="S.L.A.P. Hand">
                        </div>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <span class="papertitle">The S.L.A.P. Hand - Gesture-Controlled Robotic Hand</span>
                        <br>
                        <strong>Vivekananda Swamy Mattam</strong>
                        <br>
                        <em>Undergraduate Major Project</em>
                        <br>
                        <p></p>
                        <p>
                            S.L.A.P. (Simultaneous Linked Articulation Project) started as my undergraduate major project 
                            and has evolved significantly. Began with Arduino and flex sensors for basic finger tracking, 
                            then transitioned to Propeller microcontrollers for better multi-servo control, and eventually 
                            moved to Raspberry Pi. The biggest shift came when I moved from flex sensors to vision-based 
                            manipulation using Google's Mediapipe for hand tracking, enabling more natural gesture control 
                            without wearable sensors. The system now includes haptic feedback for tactile sensing.
                        </p>
                        <p><em>Tech: Raspberry Pi, Arduino, Propeller, Google Mediapipe, MPU6050, Haptic Feedback</em></p>
                    </td>
                </tr>

                <!-- 7) SCARA Manipulator -->
                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                            <img src="images/scara.jpg" width="200" alt="SCARA Manipulator">
                        </div>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <span class="papertitle">SCARA Manipulator Control & Planning</span>
                        <br>
                        <strong>Vivekananda Swamy Mattam</strong>
                        <br>
                        <em>Foundations of Robotics, NYU</em>
                        <br>
                        <p></p>
                        <p>
                            Three-phase project building progressive control systems for a 4-DOF SCARA manipulator. 
                            Implemented inverse kinematics using Jacobian methods, added real-time obstacle avoidance 
                            with Null-Space Projection, and designed dynamic control with trapezoidal velocity profiles 
                            accounting for inertia and external forces.
                        </p>
                        <p><em>Tech: MATLAB, Simulink, VR Visualization</em></p>
                    </td>
                </tr>

                <!-- 8) B.A.R.K. Door -->
                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                            <img src="images/bark.jpg" width="200" alt="B.A.R.K. Door">
                        </div>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <span class="papertitle">B.A.R.K. Door - IoT Pet Access System</span>
                        <br>
                        <strong>Vivekananda Swamy Mattam</strong>
                        <br>
                        <em>Personal Project</em>
                        <br>
                        <p></p>
                        <p>
                            B.A.R.K. (Bluetooth Actuated Remote Key) Door is a smart pet door using RFID tags to recognize 
                            authorized pets and Bluetooth for manual control. Built with a BS2 microcontroller and servo 
                            mechanisms for the locking system. Currently exploring Wi-Fi integration and AI-based behavioral 
                            tracking for smarter automation.
                        </p>
                        <p><em>Tech: BS2, RFID, Bluetooth, IoT, Servo Mechanisms</em></p>
                    </td>
                </tr>

                <!-- 9) E.S.V.C. -->
                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                            <img src="images/esvc.jpg" width="200" alt="E.S.V.C.">
                        </div>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <span class="papertitle">E.S.V.C. - Solar-Powered Electric Vehicle</span>
                        <br>
                        <strong>Vivekananda Swamy Mattam</strong>, Team Solarians 4.0
                        <br>
                        <em>Electric Solar Vehicle Championship</em>
                        <br>
                        <p></p>
                        <p>
                            Designed the chassis for our entry in the Electric Solar Vehicle Championship (competing against 
                            60+ teams). Using CATIA V5 for CAD and ANSYS R16.2 for structural analysis, optimized an AISI 4130 
                            steel tubular frame to balance lightweight design with racing durability while meeting ESVC 
                            safety requirements.
                        </p>
                        <p><em>Tech: CATIA V5, ANSYS R16.2</em></p>
                    </td>
                </tr>

                </tbody>
            </table>

            <!-- Skills Section -->
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
                        <h2>Technical Skills</h2>
                        <p>
                            <strong>Languages:</strong> Python, C++, JavaScript, TypeScript, MATLAB<br>
                            <strong>Frameworks & Tools:</strong> ROS, ROS 2, React, OpenCV, TensorFlow<br>
                            <strong>Hardware & Systems:</strong> Arduino, ESP32, Jetson Orin Nano, Embedded Systems, SLAM
                        </p>
                    </td>
                </tr>
                </tbody>
            </table>

            <!-- Education Section -->
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
                        <h2>Education</h2>
                        <p>
                            <strong>M.S. Mechatronics and Robotics</strong><br>
                            New York University, Tandon School of Engineering<br>
                            <em>Expected 2026</em>
                        </p>
                    </td>
                </tr>
                </tbody>
            </table>

            <!-- Footer -->
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:0px">
                        <br>
                        <p style="text-align:center;font-size:small;">
                            Template from <a href="https://jonbarron.info/">Jon Barron</a>. 
                            Last updated: January 2025.
                        </p>
                    </td>
                </tr>
                </tbody>
            </table>

        </td>
    </tr>
    </tbody>
</table>
</body>
</html>
